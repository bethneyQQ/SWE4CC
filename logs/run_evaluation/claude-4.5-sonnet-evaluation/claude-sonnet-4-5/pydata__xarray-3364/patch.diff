--- a/xarray/core/concat.py
+++ b/xarray/core/concat.py
@@ -1,4 +1,5 @@
 import pandas as pd
+import numpy as np
 
 from . import dtypes, utils
 from .alignment import align
@@ -310,19 +311,17 @@ def _dataset_concat(
     result_vars = {}
     if variables_to_merge:
         to_merge = {var: [] for var in variables_to_merge}
 
         for ds in datasets:
-            absent_merge_vars = variables_to_merge - set(ds.variables)
-            if absent_merge_vars:
-                raise ValueError(
-                    "variables %r are present in some datasets but not others. "
-                    % absent_merge_vars
-                )
-
             for var in variables_to_merge:
-                to_merge[var].append(ds.variables[var])
+                if var in ds.variables:
+                    to_merge[var].append(ds.variables[var])
 
         for var in variables_to_merge:
-            result_vars[var] = unique_variable(
-                var, to_merge[var], compat=compat, equals=equals.get(var, None)
-            )
+            if to_merge[var]:
+                result_vars[var] = unique_variable(
+                    var, to_merge[var], compat=compat, equals=equals.get(var, None)
+                )
     else:
         result_vars = {}
     result_vars.update(dim_coords)
@@ -356,13 +355,32 @@ def _dataset_concat(
 
     # stack up each variable to fill-out the dataset (in order)
     # n.b. this loop preserves variable order, needed for groupby.
-    for k in datasets[0].variables:
+    # Collect all variables to concatenate from all datasets
+    all_vars_to_concat = set()
+    for ds in datasets:
+        all_vars_to_concat.update(k for k in ds.variables if k in concat_over)
+    
+    for k in all_vars_to_concat:
         if k in concat_over:
-            try:
-                vars = ensure_common_dims([ds.variables[k] for ds in datasets])
-            except KeyError:
-                raise ValueError("%r is not present in all datasets." % k)
-            combined = concat_vars(vars, dim, positions)
+            # Collect variables, creating dummy variables for missing ones
+            vars_to_concat = []
+            for ds, dim_len in zip(datasets, concat_dim_lengths):
+                if k in ds.variables:
+                    vars_to_concat.append(ds.variables[k])
+                else:
+                    # Create a dummy variable filled with fill_value (NaN by default)
+                    # Use the first available variable to determine dimensions and attributes
+                    first_var = next((ds2.variables[k] for ds2 in datasets if k in ds2.variables), None)
+                    if first_var is not None:
+                        # Create dims for the missing variable, using concat dim length from current dataset
+                        dims = first_var.dims
+                        shape = tuple(dim_len if d == dim else dims_sizes.get(d, 1) for d in dims)
+                        data = np.full(shape, fill_value if fill_value is not dtypes.NA else np.nan)
+                        dummy_var = Variable(dims, data, first_var.attrs)
+                        vars_to_concat.append(dummy_var)
+            
+            vars = ensure_common_dims(vars_to_concat)
+            combined = concat_vars(list(vars), dim, positions)
             assert isinstance(combined, Variable)
             result_vars[k] = combined
 
 
 
