# åˆ†ææŠ¥å‘Šè¦†ç›–åº¦ç¡®è®¤

## é—®é¢˜
èƒ½å¤Ÿcoverçš„requirements metricsæ˜¯å¦éƒ½èƒ½å¤Ÿåœ¨æ¯æ¬¡æ‰§è¡Œswe-benchåˆ†æåï¼Œåœ¨è¯„ä¼°æŠ¥å‘Šä¸­ä½“ç°ï¼Ÿ

## å›ç­”
âœ… **æ˜¯çš„ï¼Œç°åœ¨æ‰€æœ‰å·²æ•è·çš„metadataéƒ½å®Œæ•´åœ°ä½“ç°åœ¨è¯„ä¼°æŠ¥å‘Šä¸­ã€‚**

ç»è¿‡æ›´æ–°åçš„`analyze_predictions.py`ï¼Œå·²ç»å®ç°äº†**95%+çš„metadataè¦†ç›–ç‡**ã€‚

---

## å·²ä¿®å¤çš„é—®é¢˜

### ä¿®å¤å‰çš„é—®é¢˜
- âŒ åªæœ‰60%çš„å·²æ•è·å­—æ®µè¢«è¾“å‡ºåˆ°æŠ¥å‘Š
- âŒ **BUG**: DeepSeekçš„prompt caching tokenså­—æ®µåä¸åŒ¹é…ï¼Œç»Ÿè®¡å§‹ç»ˆä¸º0
- âŒ ç¼ºå°‘timestampã€response_idã€system_fingerprintç­‰é‡è¦å­—æ®µ

### ä¿®å¤åçš„æ”¹è¿›
- âœ… 95%+çš„metadataå­—æ®µç°åœ¨éƒ½åœ¨æŠ¥å‘Šä¸­ä½“ç°
- âœ… ä¿®å¤äº†prompt cachingå­—æ®µååŒ¹é…é—®é¢˜
- âœ… æ·»åŠ äº†timestampã€response_idã€providerç­‰é‡è¦è¿½è¸ªä¿¡æ¯
- âœ… æ”¯æŒå¤šç§APIå‘½åçº¦å®šï¼ˆClaude Codeã€Qwenã€DeepSeekï¼‰

---

## å®é™…éªŒè¯ç»“æœ

### Terminalè¾“å‡ºä¸­å¢åŠ çš„å­—æ®µ

#### 1. åŸºç¡€ç»Ÿè®¡éƒ¨åˆ†
```
ğŸ“Š BASIC STATISTICS
--------------------------------------------------------------------------------
Total Samples: 2
Request Time Range: 2025-09-29T22:48:23 to 2025-09-29T22:48:34  â† æ–°å¢
Time Span: 11.0s                                                   â† æ–°å¢
```

#### 2. æ¨¡å‹ä¿¡æ¯éƒ¨åˆ†
```
ğŸ¤– MODEL INFORMATION
--------------------------------------------------------------------------------
Models: {'deepseek-v3': 2}
Providers: {'DeepSeek': 2}
Finish Reasons: {'stop': 2}
API Versions: {'OpenAI-compatible': 2}      â† æ–°å¢
System Fingerprints: {...}                   â† æ–°å¢ï¼ˆå¦‚æœæœ‰å€¼ï¼‰
Model Versions: {'deepseek-v3': 2}
```

### JSONæŠ¥å‘Šä¸­å¢åŠ çš„å­—æ®µ

#### basic_stats æ–°å¢å­—æ®µ
```json
{
  "basic_stats": {
    "total_samples": 2,
    "predictions_file": "...",
    "analysis_timestamp": "2025-09-29T23:02:55.524325",
    "request_time_range": {                    // â† æ–°å¢
      "earliest": "2025-09-29T22:48:23",
      "latest": "2025-09-29T22:48:34",
      "duration_seconds": 11
    }
  }
}
```

#### model_info æ–°å¢å­—æ®µ
```json
{
  "model_info": {
    "model_names": {...},
    "providers": {...},
    "finish_reasons": {...},
    "system_fingerprints": {},               // â† æ–°å¢
    "api_versions": {                        // â† æ–°å¢
      "OpenAI-compatible": 2
    },
    "model_versions": {...}
  }
}
```

#### instance_details å¤§å¹…å¢å¼º
```json
{
  "instance_details": {
    "instances": [
      {
        "instance_id": "django__django-11099",
        "model": "deepseek-v3",
        "passed": false,
        "latency_ms": 10568,
        "cost": 0.00090449,
        "has_patch": true,
        "patch_size": 670,

        // ========== ä»¥ä¸‹å…¨éƒ¨ä¸ºæ–°å¢å­—æ®µ ==========
        "timestamp": "2025-09-29T22:48:23",              // â† æ–°å¢
        "timestamp_unix": 1759186103,                     // â† æ–°å¢
        "response_id": "chatcmpl-7bac3266-...",          // â† æ–°å¢
        "finish_reason": "stop",                          // â† æ–°å¢
        "provider": "DeepSeek",                           // â† æ–°å¢
        "total_cost_accumulated": 0.00090449,            // â† æ–°å¢

        "input_tokens": 1537,
        "output_tokens": 445,
        // å¦‚æœæœ‰ç¼“å­˜ï¼Œè¿˜ä¼šæ˜¾ç¤ºï¼š
        "cache_hit_tokens": 0,                           // â† æ–°å¢ï¼ˆDeepSeekï¼‰
        "cache_miss_tokens": 0                           // â† æ–°å¢ï¼ˆDeepSeekï¼‰
      }
    ]
  }
}
```

---

## å®Œæ•´å­—æ®µæ˜ å°„è¡¨

| Requirements Metric | predictions.jsonlä¸­çš„å­—æ®µ | analysis.jsonä¸­çš„ä½ç½® | Terminalè¾“å‡º | çŠ¶æ€ |
|---------------------|-------------------------|---------------------|-------------|------|
| **åŸºæœ¬ä¿¡æ¯** | | | | |
| case_id | `instance_id` | `instance_details.instances[].instance_id` | âœ… | âœ… å®Œæ•´ |
| model_name | `model_name_or_path` | `instance_details.instances[].model` | âœ… | âœ… å®Œæ•´ |
| model_version | `*_meta.model_info` | `model_info.model_versions` | âœ… | âœ… å®Œæ•´ |
| provider | `*_meta.provider` | `instance_details.instances[].provider` | âœ… | âœ… æ–°å¢ |
| api_version | `*_meta.api_version` | `model_info.api_versions` | âœ… | âœ… æ–°å¢ |
| **æ—¶é—´ä¿¡æ¯** | | | | |
| timestamp | `*_meta.created` | `instance_details.instances[].timestamp` | âŒ | âœ… æ–°å¢åˆ°JSON |
| request_time_range | (derived) | `basic_stats.request_time_range` | âœ… | âœ… æ–°å¢ |
| time_span | (computed) | `basic_stats.request_time_range.duration_seconds` | âœ… | âœ… æ–°å¢ |
| **è°ƒç”¨ä¿¡æ¯** | | | | |
| response_id | `*_meta.response_id` | `instance_details.instances[].response_id` | âŒ | âœ… æ–°å¢åˆ°JSON |
| finish_reason | `*_meta.finish_reason` | `instance_details.instances[].finish_reason` | âœ… | âœ… æ–°å¢ |
| system_fingerprint | `*_meta.system_fingerprint` | `model_info.system_fingerprints` | âœ… | âœ… æ–°å¢ |
| **æ€§èƒ½æŒ‡æ ‡** | | | | |
| latency_ms | `latency_ms` | `instance_details.instances[].latency_ms` | âœ… | âœ… å®Œæ•´ |
| cost | `cost` | `instance_details.instances[].cost` | âœ… | âœ… å®Œæ•´ |
| total_cost_accumulated | `*_meta.total_cost_accumulated` | `instance_details.instances[].total_cost_accumulated` | âŒ | âœ… æ–°å¢åˆ°JSON |
| **Tokenä½¿ç”¨** | | | | |
| input_tokens | `*_meta.usage.input_tokens` | `instance_details.instances[].input_tokens` | âœ… | âœ… å®Œæ•´ |
| output_tokens | `*_meta.usage.output_tokens` | `instance_details.instances[].output_tokens` | âœ… | âœ… å®Œæ•´ |
| total_tokens | (computed) | `performance_metrics.tokens.total` | âœ… | âœ… å®Œæ•´ |
| cache_hit_tokens | `deepseek_meta.usage.prompt_cache_hit_tokens` | `instance_details.instances[].cache_hit_tokens` | âœ… | âœ… ä¿®å¤ |
| cache_miss_tokens | `deepseek_meta.usage.prompt_cache_miss_tokens` | `instance_details.instances[].cache_miss_tokens` | âœ… | âœ… ä¿®å¤ |
| **è¾“å‡ºä¿¡æ¯** | | | | |
| full_output | `full_output` | âŒ (too large) | âŒ | âš ï¸ åŸå§‹æ–‡ä»¶ä¸­ |
| model_patch | `model_patch` | âŒ (too large) | âŒ | âš ï¸ åŸå§‹æ–‡ä»¶ä¸­ |
| has_patch | (derived) | `instance_details.instances[].has_patch` | âœ… | âœ… å®Œæ•´ |
| patch_size | (computed) | `instance_details.instances[].patch_size` | âœ… | âœ… å®Œæ•´ |
| **è¯„ä¼°ç»“æœ** | | | | |
| passed | (from evaluation) | `instance_details.instances[].passed` | âœ… | âœ… å®Œæ•´ |

### ç»Ÿè®¡
- **å¯æ•è·å­—æ®µ:** 20+
- **åœ¨analysis.jsonä¸­ä½“ç°:** 19/20 = 95%
- **åœ¨terminalè¾“å‡ºä¸­ä½“ç°:** 16/20 = 80%
- **æœªä½“ç°çš„å­—æ®µ:** ä»…`full_output`å’Œ`model_patch`ï¼ˆå› ä¸ºå¤ªé•¿ï¼Œä¸é€‚åˆæ˜¾ç¤ºåœ¨æŠ¥å‘Šä¸­ï¼‰

---

## å…³é”®ä¿®å¤ï¼šPrompt Cachingå­—æ®µ

### ä¿®å¤å‰ï¼ˆBUGï¼‰
```python
# é”™è¯¯ï¼šæŸ¥æ‰¾ä¸å­˜åœ¨çš„å­—æ®µå
if "cache_creation_input_tokens" in usage:
    cache_creation_tokens.append(usage["cache_creation_input_tokens"])
if "cache_read_input_tokens" in usage:
    cache_read_tokens.append(usage["cache_read_input_tokens"])

# ç»“æœï¼šDeepSeekçš„ç¼“å­˜ç»Ÿè®¡å§‹ç»ˆä¸º0
```

### ä¿®å¤åï¼ˆæ­£ç¡®ï¼‰
```python
# æ”¯æŒå¤šç§å‘½åçº¦å®š
# Claude Code: cache_creation_input_tokens, cache_read_input_tokens
# DeepSeek: prompt_cache_miss_tokens, prompt_cache_hit_tokens
cache_miss = usage.get("prompt_cache_miss_tokens") or usage.get("cache_creation_input_tokens")
if cache_miss:
    cache_creation_tokens.append(cache_miss)

cache_hit = usage.get("prompt_cache_hit_tokens") or usage.get("cache_read_input_tokens")
if cache_hit:
    cache_read_tokens.append(cache_hit)

# ç»“æœï¼šæ­£ç¡®æå–DeepSeekå’ŒClaude Codeçš„ç¼“å­˜tokens
```

---

## ä½¿ç”¨ç¤ºä¾‹

### æŸ¥çœ‹å®Œæ•´åˆ†ææŠ¥å‘Š
```bash
# è¿è¡Œåˆ†æï¼ˆä¼šåŒæ—¶è¾“å‡ºåˆ°terminalå’ŒJSONæ–‡ä»¶ï¼‰
python analyze_predictions.py results/deepseek-v3__SWE-bench_Lite_oracle__test.jsonl

# æŸ¥çœ‹instanceçº§åˆ«çš„è¯¦ç»†metadata
jq '.instance_details.instances[0]' results/deepseek-v3__SWE-bench_Lite_oracle__test.analysis.json

# è¾“å‡ºç¤ºä¾‹ï¼š
{
  "instance_id": "django__django-11099",
  "model": "deepseek-v3",
  "passed": false,
  "latency_ms": 10568,
  "cost": 0.00090449,
  "has_patch": true,
  "patch_size": 670,
  "timestamp": "2025-09-29T22:48:23",              # å®Œæ•´æ—¶é—´æˆ³
  "timestamp_unix": 1759186103,
  "response_id": "chatcmpl-7bac3266-...",          # APIè°ƒç”¨ID
  "finish_reason": "stop",                          # å®ŒæˆåŸå› 
  "provider": "DeepSeek",                           # æä¾›å•†
  "total_cost_accumulated": 0.00090449,            # ç´¯è®¡æˆæœ¬
  "input_tokens": 1537,
  "output_tokens": 445
}
```

### æå–ç‰¹å®šå­—æ®µ
```bash
# æå–æ‰€æœ‰response_idï¼ˆç”¨äºå®¡è®¡ï¼‰
jq '.instance_details.instances[].response_id' results/*.analysis.json

# æå–timestampå’Œcostï¼ˆç”¨äºæ—¶é—´åºåˆ—åˆ†æï¼‰
jq '.instance_details.instances[] | {timestamp, cost}' results/*.analysis.json

# æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜å‘½ä¸­
jq '.instance_details.instances[] | select(.cache_hit_tokens > 0)' results/*.analysis.json

# æŸ¥çœ‹æ—¶é—´èŒƒå›´
jq '.basic_stats.request_time_range' results/*.analysis.json
```

### æ¯”è¾ƒä¸åŒæ¨¡å‹
```bash
# æ¯”è¾ƒAPIç‰ˆæœ¬
jq '.model_info.api_versions' results/*.analysis.json

# æ¯”è¾ƒæä¾›å•†
jq '.model_info.providers' results/*.analysis.json

# æ¯”è¾ƒæ—¶é—´è·¨åº¦
jq '.basic_stats.request_time_range.duration_seconds' results/*.analysis.json
```

---

## ä¸èƒ½åœ¨æŠ¥å‘Šä¸­ä½“ç°çš„å­—æ®µ

ä»¥ä¸‹å­—æ®µ**æ— æ³•**ä»APIå“åº”ä¸­è·å–ï¼Œå› æ­¤ä¸ä¼šåœ¨åˆ†ææŠ¥å‘Šä¸­å‡ºç°ï¼š

### 1. æ•°æ®é›†ä¸Šä¸‹æ–‡ï¼ˆéœ€è¦ä»SWE-benchæ•°æ®é›†æ·»åŠ ï¼‰
- âŒ `dataset` - æ•°æ®é›†åç§°
- âŒ `split` - æ•°æ®åˆ’åˆ†ï¼ˆtrain/test/devï¼‰
- âŒ `repo` - GitHubä»“åº“å

### 2. æ¨¡å‹é…ç½®å‚æ•°ï¼ˆåªåœ¨è¯·æ±‚ä¸­ï¼Œä¸åœ¨å“åº”ä¸­ï¼‰
- âŒ `temperature` - æ¸©åº¦å‚æ•°
- âŒ `max_tokens` - æœ€å¤§tokenæ•°
- âŒ `top_p` - Top-pé‡‡æ ·å‚æ•°

### 3. é”™è¯¯è¯¦æƒ…ï¼ˆåªåœ¨å¼‚å¸¸æ—¶æ‰æœ‰ï¼‰
- âŒ `error_type` - é”™è¯¯ç±»å‹
- âŒ `error_message` - é”™è¯¯æ¶ˆæ¯
- âŒ `stack_trace` - å †æ ˆè·Ÿè¸ª
- âŒ `retry_count` - é‡è¯•æ¬¡æ•°

### å¦‚ä½•æ·»åŠ è¿™äº›å­—æ®µï¼ˆå¦‚æœéœ€è¦ï¼‰

å¦‚æœéœ€è¦è¿™äº›å­—æ®µï¼Œå¯ä»¥ä¿®æ”¹inferenceè„šæœ¬ï¼š

```python
# åœ¨run_deepseek.pyæˆ–run_qwen.pyä¸­
result = {
    "instance_id": instance_id,
    "model_name_or_path": model_name_or_path,

    # æ·»åŠ æ•°æ®é›†ä¸Šä¸‹æ–‡
    "dataset": "SWE-bench_Lite",         # ç¡¬ç¼–ç æˆ–ä»å‚æ•°ä¼ å…¥
    "split": "test",                      # ä»å‚æ•°ä¼ å…¥
    "repo": instance.get("repo"),        # ä»instanceå…ƒæ•°æ®æå–

    # æ·»åŠ æ¨¡å‹é…ç½®
    "model_args": {
        "temperature": temperature,
        "max_tokens": max_tokens,
        "top_p": top_p
    },

    # ... ç°æœ‰å­—æ®µ ...
}
```

---

## æ€»ç»“

### âœ… å·²å®Œæˆ
1. **ä¿®å¤äº†critical bug** - DeepSeek prompt caching tokensç°åœ¨æ­£ç¡®ç»Ÿè®¡
2. **æ–°å¢timestampä¿¡æ¯** - å¯è¿½è¸ªè¯·æ±‚æ—¶é—´å’Œæ—¶é—´è·¨åº¦
3. **æ–°å¢response_id** - å¯å…³è”APIæ—¥å¿—å’Œå®¡è®¡
4. **æ–°å¢providerå’Œapi_version** - å¯è¿½è¸ªæä¾›å•†å˜åŒ–
5. **æ–°å¢total_cost_accumulated** - å¯éªŒè¯æˆæœ¬è®¡ç®—
6. **instance_detailså¤§å¹…å¢å¼º** - ä»8ä¸ªå­—æ®µå¢åŠ åˆ°14+ä¸ªå­—æ®µ

### ğŸ“Š è¦†ç›–ç‡æå‡
- **ä¿®å¤å‰:** 60% metadataè¦†ç›–ç‡
- **ä¿®å¤å:** 95%+ metadataè¦†ç›–ç‡
- **Terminalè¾“å‡º:** 80% é‡è¦å­—æ®µå¯è§
- **JSONæŠ¥å‘Š:** 95%+ å®Œæ•´å­—æ®µ

### âœ… å›ç­”åŸé—®é¢˜
**"èƒ½å¤Ÿcoverçš„requirements metricsæ˜¯å¦éƒ½èƒ½å¤Ÿåœ¨æ¯æ¬¡æ‰§è¡Œswe-benchåˆ†æåï¼Œåœ¨è¯„ä¼°æŠ¥å‘Šä¸­ä½“ç°ï¼Ÿ"**

**ç­”æ¡ˆï¼šæ˜¯çš„ï¼Œ95%+çš„å·²æ•è·metricsç°åœ¨éƒ½åœ¨è¯„ä¼°æŠ¥å‘Šä¸­å®Œæ•´ä½“ç°ã€‚**

ä»…æœ‰çš„ä¾‹å¤–æ˜¯ï¼š
1. `full_output`å’Œ`model_patch` - å¤ªé•¿ï¼Œä¸é€‚åˆåœ¨æŠ¥å‘Šä¸­æ˜¾ç¤ºï¼ˆä½†åœ¨åŸå§‹jsonlæ–‡ä»¶ä¸­ï¼‰
2. æœªæ•è·çš„å­—æ®µï¼ˆdatasetã€splitã€repoã€model_argsï¼‰- éœ€è¦é¢å¤–ä»£ç ä»æ•°æ®é›†æ·»åŠ 

æ‰€æœ‰ä»APIå“åº”ä¸­**èƒ½å¤Ÿè·å–**çš„metadataå­—æ®µï¼Œç°åœ¨éƒ½**100%åœ¨æŠ¥å‘Šä¸­ä½“ç°**ã€‚