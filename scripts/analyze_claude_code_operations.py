#!/usr/bin/env python3
"""
åˆ†æClaude Codeåœ¨inferenceè¿‡ç¨‹ä¸­çš„æ‰€æœ‰æ“ä½œ
ä»response metadataä¸­æå–å·¥å…·ä½¿ç”¨è®°å½•
"""
import json
import argparse
from pathlib import Path
from collections import defaultdict
from typing import Dict, List


def extract_tool_usage(response_data: Dict) -> List[Dict]:
    """
    ä»Claude Codeå“åº”ä¸­æå–å·¥å…·ä½¿ç”¨è®°å½•

    Claude Codeçš„responseç»“æ„:
    {
        "type": "result",
        "usage": {...},
        "modelUsage": {...},
        "tool_uses": [...]  # å¯èƒ½çš„å·¥å…·ä½¿ç”¨è®°å½•
    }
    """
    tool_uses = []

    # æ–¹æ³•1: æ£€æŸ¥tool_useså­—æ®µ
    if 'tool_uses' in response_data:
        tool_uses.extend(response_data['tool_uses'])

    # æ–¹æ³•2: ä»usageä¸­æå– (å¦‚æœæœ‰server_tool_use)
    if 'usage' in response_data:
        usage = response_data['usage']
        if 'server_tool_use' in usage:
            # è¿™é‡Œå¯èƒ½åŒ…å«å·¥å…·ä½¿ç”¨ç»Ÿè®¡
            pass

    # æ–¹æ³•3: ä»å®Œæ•´å“åº”ä¸­æœç´¢å·¥å…·è°ƒç”¨æ¨¡å¼
    # Claudeå¯èƒ½åœ¨resultæ–‡æœ¬ä¸­è®°å½•äº†å·¥å…·ä½¿ç”¨

    return tool_uses


def analyze_predictions_file(predictions_file: str) -> Dict:
    """
    åˆ†æpredictionsæ–‡ä»¶ä¸­çš„Claude Codeæ“ä½œ
    """
    stats = {
        'total_instances': 0,
        'instances_with_tools': 0,
        'tool_usage_by_type': defaultdict(int),
        'file_operations': defaultdict(list),
        'instances_details': []
    }

    with open(predictions_file, 'r') as f:
        for line in f:
            data = json.loads(line)
            instance_id = data['instance_id']
            stats['total_instances'] += 1

            # æå–Claude Code metadata
            claude_meta = data.get('claude_code_meta', {})
            response_data = claude_meta.get('response_data', {})

            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†å¢å¼ºæ¨¡å¼
            is_enhanced = claude_meta.get('enhanced', False)
            has_tools = claude_meta.get('tools_available', False)

            instance_info = {
                'instance_id': instance_id,
                'enhanced': is_enhanced,
                'tools_available': has_tools,
                'tools_used': [],
                'files_accessed': [],
                'operations': []
            }

            # æå–å·¥å…·ä½¿ç”¨
            tool_uses = extract_tool_usage(response_data)
            if tool_uses:
                stats['instances_with_tools'] += 1
                for tool_use in tool_uses:
                    tool_name = tool_use.get('name', 'unknown')
                    stats['tool_usage_by_type'][tool_name] += 1
                    instance_info['tools_used'].append(tool_use)

            # å°è¯•ä»full_outputä¸­æå–æ“ä½œä¿¡æ¯
            full_output = data.get('full_output', '')
            if full_output:
                # æŸ¥æ‰¾Readæ“ä½œçš„ç—•è¿¹
                import re

                # æ¨¡å¼1: "Reading file: path/to/file.py"
                read_patterns = [
                    r'Reading (?:file )?[\'"]?([^\'"\\n]+\.py)[\'"]?',
                    r'Read\([\'"]([^\'"\\n]+)[\'"\)]',
                    r'examining ([^\\s]+\.py)',
                    r'looking at ([^\\s]+\.py)',
                ]

                for pattern in read_patterns:
                    matches = re.findall(pattern, full_output, re.IGNORECASE)
                    for match in matches:
                        if match not in instance_info['files_accessed']:
                            instance_info['files_accessed'].append(match)
                            stats['file_operations'][match].append(instance_id)

                # æ¨¡å¼2: Bashæ“ä½œ
                bash_patterns = [
                    r'(?:Running|Executing) bash: (.+)',
                    r'`([^`]+)`',  # ä»£ç å—ä¸­çš„å‘½ä»¤
                ]

                for pattern in bash_patterns:
                    matches = re.findall(pattern, full_output)
                    for match in matches[:5]:  # é™åˆ¶æ•°é‡
                        if any(cmd in match.lower() for cmd in ['ls', 'find', 'grep', 'cd', 'pwd']):
                            instance_info['operations'].append({
                                'type': 'bash',
                                'command': match
                            })

            # ä»repo_pathè·å–è®¿é—®çš„ä»“åº“
            if 'repo_path' in data:
                instance_info['repo_path'] = data['repo_path']

            stats['instances_details'].append(instance_info)

    return stats


def print_summary(stats: Dict):
    """æ‰“å°ç»Ÿè®¡æ‘˜è¦"""
    print("=" * 80)
    print("Claude Codeæ“ä½œåˆ†ææŠ¥å‘Š")
    print("=" * 80)

    print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"  æ€»å®ä¾‹æ•°: {stats['total_instances']}")
    print(f"  ä½¿ç”¨å·¥å…·çš„å®ä¾‹: {stats['instances_with_tools']}")
    print(f"  å·¥å…·ä½¿ç”¨ç‡: {stats['instances_with_tools']/stats['total_instances']*100:.1f}%")

    print(f"\nğŸ”§ å·¥å…·ä½¿ç”¨ç»Ÿè®¡:")
    if stats['tool_usage_by_type']:
        for tool, count in sorted(stats['tool_usage_by_type'].items(), key=lambda x: -x[1]):
            print(f"  {tool}: {count} æ¬¡")
    else:
        print("  (ä»metadataä¸­æœªæ£€æµ‹åˆ°æ˜¾å¼çš„å·¥å…·ä½¿ç”¨è®°å½•)")

    print(f"\nğŸ“ æ–‡ä»¶è®¿é—®ç»Ÿè®¡:")
    if stats['file_operations']:
        print(f"  è®¿é—®çš„æ–‡ä»¶æ€»æ•°: {len(stats['file_operations'])}")
        print(f"\n  çƒ­é—¨æ–‡ä»¶ (Top 10):")
        sorted_files = sorted(stats['file_operations'].items(), key=lambda x: -len(x[1]))
        for file, instances in sorted_files[:10]:
            print(f"    {file}: {len(instances)} ä¸ªå®ä¾‹")
    else:
        print("  (ä»è¾“å‡ºä¸­æœªæ£€æµ‹åˆ°æ˜ç¡®çš„æ–‡ä»¶è®¿é—®è®°å½•)")

    print(f"\nğŸ“‹ å®ä¾‹è¯¦æƒ…:")
    for instance in stats['instances_details']:
        print(f"\n  ğŸ”¹ {instance['instance_id']}")
        print(f"    å¢å¼ºæ¨¡å¼: {'æ˜¯' if instance['enhanced'] else 'å¦'}")
        print(f"    å·¥å…·å¯ç”¨: {'æ˜¯' if instance['tools_available'] else 'å¦'}")

        if instance['files_accessed']:
            print(f"    è®¿é—®çš„æ–‡ä»¶: {len(instance['files_accessed'])} ä¸ª")
            for f in instance['files_accessed'][:3]:
                print(f"      - {f}")
            if len(instance['files_accessed']) > 3:
                print(f"      ... è¿˜æœ‰ {len(instance['files_accessed']) - 3} ä¸ª")

        if instance['operations']:
            print(f"    æ‰§è¡Œçš„æ“ä½œ: {len(instance['operations'])} ä¸ª")
            for op in instance['operations'][:2]:
                print(f"      - {op['type']}: {op['command'][:60]}...")

        if 'repo_path' in instance:
            print(f"    ä»“åº“è·¯å¾„: {instance['repo_path']}")


def export_detailed_report(stats: Dict, output_file: str):
    """å¯¼å‡ºè¯¦ç»†çš„JSONæŠ¥å‘Š"""
    with open(output_file, 'w') as f:
        json.dump(stats, f, indent=2)
    print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {output_file}")


def check_actual_tool_usage(predictions_file: str):
    """
    æ£€æŸ¥å®é™…çš„å·¥å…·ä½¿ç”¨æƒ…å†µ
    é€šè¿‡åˆ†æClaudeçš„å“åº”å†…å®¹æ¥æ¨æ–­å·¥å…·ä½¿ç”¨
    """
    print("\n" + "=" * 80)
    print("ğŸ” æ·±åº¦åˆ†æ: Claude Codeå·¥å…·ä½¿ç”¨æ¨æ–­")
    print("=" * 80)

    with open(predictions_file, 'r') as f:
        for line_num, line in enumerate(f, 1):
            data = json.loads(line)
            instance_id = data['instance_id']
            full_output = data.get('full_output', '')

            print(f"\nğŸ“Œ Instance: {instance_id}")
            print("-" * 80)

            # åˆ†æè¾“å‡ºå†…å®¹
            indicators = {
                'read_file': [
                    'I can see', 'Looking at', 'Reading', 'The file contains',
                    'examining the', 'After reading', 'Based on the file'
                ],
                'bash': [
                    'Running', 'Executing', 'Using bash', 'I ran', 'I executed',
                    'found the following', 'located in'
                ],
                'grep': [
                    'Searching for', 'I searched', 'grep shows', 'pattern match',
                    'I found these occurrences'
                ],
                'direct_answer': [
                    'Based on the problem', 'Here\'s the patch', 'The issue is',
                    'I can see you\'ve shared'  # è¿™ä¸ªè¡¨ç¤ºæ²¡ç”¨å·¥å…·
                ]
            }

            detected_tools = []
            evidence = []

            for tool, patterns in indicators.items():
                for pattern in patterns:
                    if pattern.lower() in full_output.lower():
                        if tool not in detected_tools:
                            detected_tools.append(tool)
                        # æå–ä¸Šä¸‹æ–‡
                        idx = full_output.lower().find(pattern.lower())
                        context = full_output[max(0, idx-20):min(len(full_output), idx+80)]
                        evidence.append({
                            'tool': tool,
                            'pattern': pattern,
                            'context': context.replace('\n', ' ')
                        })
                        break  # æ‰¾åˆ°ä¸€ä¸ªå°±å¤Ÿäº†

            if detected_tools:
                print(f"  æ£€æµ‹åˆ°çš„å·¥å…·ä½¿ç”¨: {', '.join(detected_tools)}")
                print(f"\n  è¯æ®:")
                for ev in evidence[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    print(f"    [{ev['tool']}] ...{ev['context']}...")
            else:
                print(f"  âš ï¸  æœªæ£€æµ‹åˆ°æ˜ç¡®çš„å·¥å…·ä½¿ç”¨è¿¹è±¡")
                # æ˜¾ç¤ºå“åº”çš„å¼€å¤´
                preview = full_output[:200].replace('\n', ' ')
                print(f"  å“åº”é¢„è§ˆ: {preview}...")


def main():
    parser = argparse.ArgumentParser(
        description='åˆ†æClaude Codeçš„æ“ä½œè®°å½•'
    )
    parser.add_argument(
        '--predictions_file',
        required=True,
        help='Predictions JSONLæ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--output',
        help='è¾“å‡ºè¯¦ç»†æŠ¥å‘Šçš„JSONæ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--deep-analysis',
        action='store_true',
        help='å¯ç”¨æ·±åº¦åˆ†æï¼ˆä»å“åº”å†…å®¹æ¨æ–­å·¥å…·ä½¿ç”¨ï¼‰'
    )

    args = parser.parse_args()

    # åˆ†ææ–‡ä»¶
    stats = analyze_predictions_file(args.predictions_file)

    # æ‰“å°æ‘˜è¦
    print_summary(stats)

    # æ·±åº¦åˆ†æ
    if args.deep_analysis:
        check_actual_tool_usage(args.predictions_file)

    # å¯¼å‡ºæŠ¥å‘Š
    if args.output:
        export_detailed_report(stats, args.output)

    print("\n" + "=" * 80)
    print("âœ… åˆ†æå®Œæˆ")
    print("=" * 80)


if __name__ == '__main__':
    main()
